{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supertonic-2 QNN Porting Guide\n",
    "\n",
    "This notebook walks through the complete process of porting **Supertone/supertonic-2** TTS model to Qualcomm QNN for deployment on QCS6490.\n",
    "\n",
    "**Model**: [Supertone/supertonic-2](https://huggingface.co/Supertone/supertonic-2) (66M params, ONNX)\n",
    "\n",
    "## Pipeline Architecture\n",
    "\n",
    "```\n",
    "Text Input → [Duration Predictor] → duration\n",
    "          → [Text Encoder] → text_emb  \n",
    "          → [Vector Estimator x N steps] → denoised_latent\n",
    "          → [Vocoder] → Audio WAV (44.1kHz)\n",
    "```\n",
    "\n",
    "## Model Specifications (Actual ONNX Shapes)\n",
    "\n",
    "| Model | Size | Key Inputs | Output |\n",
    "|-------|------|------------|--------|\n",
    "| Duration Predictor | 1.5 MB | text_ids [1,seq], style_dp [1,8,16], text_mask [1,1,seq] | duration [1] |\n",
    "| Text Encoder | 27 MB | text_ids [1,seq], style_ttl [1,50,256], text_mask [1,1,seq] | text_emb [1,256,seq] |\n",
    "| Vector Estimator | 132 MB | noisy_latent [1,144,lat], text_emb [1,256,seq], +5 more | denoised_latent [1,144,lat] |\n",
    "| Vocoder | 101 MB | latent [1,144,lat] | wav_tts [1,samples] |\n",
    "\n",
    "Note: `seq` = text sequence length (dynamic), `lat` = latent length (dynamic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Calibration Data\n",
    "\n",
    "Run the ONNX models with representative inputs to create calibration data for QNN quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] QAIRT_SDK_ROOT=/opt/qcom/aistack/qairt/2.37.1.250807\n",
      "[WARN] QNN_SDK_ROOT/SNPE_ROOT set to QAIRT_SDK_ROOT for backwards compatibility and will be deprecated in a future release.\n",
      "[INFO] QAIRT SDK environment setup complete\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "unset PYTHONPATH\n",
    "unset LD_LIBRARY_PATH\n",
    "source /opt/qcom/aistack/qairt/2.37.1.250807/bin/envsetup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ONNX → QNN Conversion\n",
    "\n",
    "Convert each ONNX model to QNN format with HTP (Hexagon Tensor Processor) optimization and 8-bit quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Convert Duration Predictor\n",
    "unset PYTHONPATH\n",
    "unset LD_LIBRARY_PATH\n",
    "source /opt/qcom/aistack/qairt/2.37.1.250807/bin/envsetup.sh\n",
    "\n",
    "qnn-onnx-converter \\\n",
    "    --input_network ./model/onnx/duration_predictor.onnx \\\n",
    "    --input_dim text_ids 1,128 \\\n",
    "    --input_dim style_dp 1,8,16 \\\n",
    "    --input_dim text_mask 1,1,128 \\\n",
    "    --output_path ./QNN_Models/duration_predictor_htp.cpp \\\n",
    "    --input_list ./calibration_data/duration_predictor_input_list.txt \\\n",
    "    --param_quantizer tf \\\n",
    "    --act_quantizer tf \\\n",
    "    --weights_bitwidth 8 \\\n",
    "    --act_bitwidth 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Compile all 4 models for aarch64 target\n",
    "unset LD_LIBRARY_PATH\n",
    "source /opt/qcom-sdk/environment-setup-armv8-2a-qcom-linux\n",
    "source /opt/qcom/aistack/qairt/2.37.1.250807/bin/envsetup.sh\n",
    "\n",
    "MODELS=(\"duration_predictor_htp\" \"text_encoder_htp\" \"vector_estimator_htp\" \"vocoder_htp\")\n",
    "\n",
    "for MODEL in \"${MODELS[@]}\"; do\n",
    "    echo \"=== Compiling $MODEL ===\"\n",
    "    qnn-model-lib-generator \\\n",
    "        -c ./QNN_Models/${MODEL}.cpp \\\n",
    "        -b ./QNN_Models/${MODEL}.bin \\\n",
    "        -o ./QNN_Model_lib/ \\\n",
    "        -t aarch64-oe-linux-gcc11.2\n",
    "done\n",
    "\n",
    "echo \"=== All models compiled ===\"\n",
    "ls -lh QNN_Model_lib/aarch64-oe-linux-gcc11.2/*.so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Configuration Notes\n",
    "\n",
    "**Quantization Settings:**\n",
    "- Weights: 8-bit (w8)\n",
    "- Activations: 8-bit (a8)\n",
    "- Float operations: 32-bit\n",
    "- Quantizers: TensorFlow (tf) for both params and activations\n",
    "\n",
    "**Critical Requirement:**\n",
    "- QNN automatically converts INT64 inputs to INT32\n",
    "- All `text_ids` inputs in calibration data must be INT32 (not INT64)\n",
    "- Other inputs (FP32) remain unchanged\n",
    "\n",
    "**Fixed Input Dimensions:**\n",
    "- text_ids: [1, 128]\n",
    "- style_dp: [1, 8, 16]\n",
    "- style_ttl: [1, 50, 256]\n",
    "- noisy_latent: [1, 144, 192]\n",
    "- latent: [1, 144, 192]\n",
    "\n",
    "## Step 3: Compile to Shared Libraries\n",
    "\n",
    "Compile all QNN models into `.so` shared libraries for ARM64 deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Convert Vector Estimator\n",
    "unset PYTHONPATH\n",
    "unset LD_LIBRARY_PATH\n",
    "source /opt/qcom/aistack/qairt/2.37.1.250807/bin/envsetup.sh\n",
    "\n",
    "qnn-onnx-converter \\\n",
    "    --input_network ./model/onnx/vector_estimator.onnx \\\n",
    "    --input_dim noisy_latent 1,144,192 \\\n",
    "    --input_dim text_emb 1,256,128 \\\n",
    "    --input_dim style_ttl 1,50,256 \\\n",
    "    --input_dim latent_mask 1,1,192 \\\n",
    "    --input_dim text_mask 1,1,128 \\\n",
    "    --input_dim current_step 1 \\\n",
    "    --input_dim total_step 1 \\\n",
    "    --output_path ./QNN_Models/vector_estimator_htp.cpp \\\n",
    "    --input_list ./calibration_data/vector_estimator_input_list.txt \\\n",
    "    --param_quantizer tf \\\n",
    "    --act_quantizer tf \\\n",
    "    --weights_bitwidth 8 \\\n",
    "    --act_bitwidth 8 \\\n",
    "    --float_bitwidth 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Convert Text Encoder\n",
    "unset PYTHONPATH\n",
    "unset LD_LIBRARY_PATH\n",
    "source /opt/qcom/aistack/qairt/2.37.1.250807/bin/envsetup.sh\n",
    "\n",
    "qnn-onnx-converter \\\n",
    "    --input_network ./model/onnx/text_encoder.onnx \\\n",
    "    --input_dim text_ids 1,128 \\\n",
    "    --input_dim style_ttl 1,50,256 \\\n",
    "    --input_dim text_mask 1,1,128 \\\n",
    "    --output_path ./QNN_Models/text_encoder_htp.cpp \\\n",
    "    --input_list ./calibration_data/text_encoder_input_list.txt \\\n",
    "    --param_quantizer tf \\\n",
    "    --act_quantizer tf \\\n",
    "    --weights_bitwidth 8 \\\n",
    "    --act_bitwidth 8 \\\n",
    "    --float_bitwidth 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK environment now set up; additionally you may now run devtool to perform development tasks.\n",
      "Run devtool --help for further details.\n",
      "[INFO] QAIRT_SDK_ROOT=/opt/qcom/aistack/qairt/2.37.1.250807\n",
      "[WARN] QNN_SDK_ROOT/SNPE_ROOT set to QAIRT_SDK_ROOT for backwards compatibility and will be deprecated in a future release.\n",
      "[INFO] QAIRT SDK environment setup complete\n",
      "2026-02-15 23:04:47,744 -    INFO - qnn-model-lib-generator: Model cpp file path  : QNN_Models/duration_predictor_htp.cpp\n",
      "2026-02-15 23:04:47,744 -    INFO - qnn-model-lib-generator: Model bin file path  : QNN_Models/duration_predictor_htp.bin\n",
      "2026-02-15 23:04:47,744 -    INFO - qnn-model-lib-generator: Library target       : [['aarch64-oe-linux-gcc11.2']]\n",
      "2026-02-15 23:04:47,744 -    INFO - qnn-model-lib-generator: Library name         : duration_predictor_htp\n",
      "2026-02-15 23:04:47,744 -    INFO - qnn-model-lib-generator: Output directory     : QNN_Model_lib\n",
      "2026-02-15 23:04:47,744 -    INFO - qnn-model-lib-generator: Output library name  : duration_predictor_htp\n",
      "2026-02-15 23:04:58,370 -    INFO - qnn-model-lib-generator: Target: aarch64-oe-linux-gcc11.2\tLibrary: /mnt/nunnari3/devansh/supertonic2-qualcomm/QNN_Model_lib/aarch64-oe-linux-gcc11.2/libduration_predictor_htp.so\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "unset LD_LIBRARY_PATH\n",
    "source /home/advantech/qcom-wayland_sdk/environment-setup-armv8-2a-qcom-linux\n",
    "source /opt/qcom/aistack/qairt/2.37.1.250807/bin/envsetup.sh\n",
    "\n",
    "qnn-model-lib-generator \\\n",
    "    -c ./QNN_Models/duration_predictor_htp.cpp \\\n",
    "    -b ./QNN_Models/duration_predictor_htp.bin \\\n",
    "    -o ./QNN_Model_lib/ \\\n",
    "    -t aarch64-oe-linux-gcc11.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
